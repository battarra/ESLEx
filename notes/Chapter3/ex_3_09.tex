%!TEX root = ../Tibt.tex

\exercise{3.9}

If we add a new predictor $\mathbf{z}$ to the fit, the residual-sum-of squares changes by:
\begin{eqnarray*}
    RSS \; \longrightarrow \; RSS - \left( \frac{ \langle \mathbf{y}, \mathbf{z}^{(r)} \rangle}{||\mathbf{z}^{(r)} ||} \right) ^2
\end{eqnarray*}
where $ \mathbf{z}^{(r)}$ is the OLS residual of $ \mathbf{z}$ against the predictors already included in the fit, $\mathbf{X}_1$ in this case. Hence, it suffices to find the matrix $\mathbf{X}_{2}^{(r)}$ of residuals,
which is easy to compute using the QR decomposition $\mathbf{X}_1 =  \mathbf{Q}R$:
\begin{eqnarray} \label{3p9_e0}
\mathbf{X}_{2}^{(r)} & = & \mathbf{X}_2 - \mathbf{X}_1 \left( \mathbf{X}_1^T \mathbf{X}_1 \right)^{-1} \mathbf{X}_1^T \mathbf{X}_2 \\
& = & \left( \mathbb{I} - \mathbf{Q} \mathbf{Q}^T \right) \mathbf{X}_2
\end{eqnarray}
Then, we choose the predictor $\mathbf{x}_{2, \bar{j}}$ such that:
\begin{eqnarray} \label{3p9_e1}
\bar{j} = \textrm{argmax}\, \frac{| \langle \mathbf{y}, \mathbf{x}_{2, j}^{(r)} \rangle |}{||\mathbf{x}_{2, j}^{(r)}||} = \textrm{argmax}\, \frac{| \langle \mathbf{r}, \mathbf{x}_{2, j}^{(r)} \rangle |}{||\mathbf{x}_{2, j}^{(r)}||} = \textrm{argmax}\, \frac{| \langle \mathbf{r}, \mathbf{x}_{2, j} \rangle |}{||\mathbf{x}_{2, j}^{(r)}||}
\end{eqnarray}
The last two equalities follows from the fact that, by construction, $\mathbf{x}_{2, j}^{(r)}$ and $\mathbf{r}$ are orthogonal to the subspace generated by the columns of $\mathbf{X}_1$, hence to $\hat{\mathbf{y}} = \mathbf{y} - \mathbf{r}$ and $\mathbf{x}_{2, j} - \mathbf{x}_{2, j}^{(r)}$. The
process can be continued by adding the column $\mathbf{x}_{2, \bar{j}}^{(r)} / ||\mathbf{x}_{2, \bar{j}}^{(r)}||$ to $Q$, and updating R according to (\ref{3p9_e0}).

Note how one has generally $||\mathbf{x}_{2, j}^{(r)}|| \leq ||\mathbf{x}_{2, j}||$, the equality holding 
only when $\mathbf{x}_{2, j}$ is orthogonal to $\mathbf{X}_1$. Hence, the criterion (\ref{3p9_e1}) is not equivalent to:
\begin{eqnarray} \label{3p9_e2}
\bar{j} = \textrm{argmax}\, \frac{| \langle \mathbf{r}, \mathbf{x}_{2, j} \rangle |}{||\mathbf{x}_{2, j}||}
\end{eqnarray}
Indeed, in forward stepwise regression we allow ourselves to change the coefficients of the predictors in the
current active set $ \mathbf{X}_1$, so as to only pick the "new" part in $\mathbf{x}_{2, j}$. Conversely, criterion (\ref{3p9_e2}), which corresponds to forward stagewise regression, tends to penalize predictors
which are strongly correlated with the predictors in the active set.